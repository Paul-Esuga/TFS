{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "usecols = [\"id\", \"date\", \"amount\", \"card_id\", \"client_id\", \"use_chip\", \"mcc\", \"errors\"]\n",
    "\n",
    "trans_data = pd.read_csv(\"transactions_data.csv\", skiprows=lambda i: i > 0 and random.random() > (200000 / 13295276), low_memory=False, usecols = usecols)\n",
    "\n",
    "trans_data[['amount']] = trans_data[['amount']].apply(lambda x: x.astype(str).str.replace('$','').astype(float))\n",
    "\n",
    "td = pd.DataFrame(trans_data)\n",
    "td['is_refund'] = td['amount'] < 0\n",
    "td[\"amount\"] = td[\"amount\"].abs()\n",
    "\n",
    "# Grouping Client IDs by Amount Ranges\n",
    "client_total_amount = td.groupby('client_id')['amount'].sum().reset_index()\n",
    "p30 = client_total_amount['amount'].quantile(0.3)\n",
    "p70 = client_total_amount['amount'].quantile(0.7)\n",
    "\n",
    "def amount_group(val):\n",
    "    if val < p30:\n",
    "        return 'XLow'\n",
    "    elif val < p70:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "# Aggregate amount per client\n",
    "client_total_amount['spend_group'] = client_total_amount['amount'].apply(amount_group)\n",
    "client_total_amount = client_total_amount.sort_values(by=\"spend_group\", ascending=False)\n",
    "\n",
    "# Assuming the 'client_id' column exists in both DataFrames\n",
    "td['spend_group'] = td['client_id'].map(client_total_amount.set_index('client_id')['spend_group'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "use_chip_risk = {\n",
    "    'Swipe Transaction': 1,\n",
    "    'Online Transaction': 0.5,\n",
    "    'Chip Transaction': 0.2\n",
    "}\n",
    "\n",
    "td['use_chip_risk'] = td['use_chip'].map(use_chip_risk)\n",
    "\n",
    "td['errors_en'] = td['errors'].notnull().astype(\"int\")\n",
    "td = td.sort_values(by = 'id', ascending = True)\n",
    "\n",
    "def normalize(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "tdT = td.copy()\n",
    "tdT['date'] = pd.to_datetime(tdT['date'], errors = \"coerce\")\n",
    "\n",
    "tdTd = tdT['date'].dt.strftime(\"%d-%m-%y %H:%M\").str.split(\" \", expand=True)\n",
    "tdT['date'] = tdTd[0].copy()\n",
    "tdT['time'] = tdTd[1].copy()\n",
    "td['date'] = pd.to_datetime(td['date'], errors = \"coerce\")\n",
    "tdT['hour'] = td['date'].dt.hour\n",
    "tdT['time_r'] = tdT['hour'].apply(lambda x: 1 if x < 5 else 0.3 if x > 22 else 0)\n",
    "\n",
    "td = tdT.copy()\n",
    "\n",
    "\n",
    "td = td[td['amount']>0]\n",
    "td[\"amount_norm\"] = np.log(td[\"amount\"] + 1)\n",
    "\n",
    "weights = {\n",
    "    'amount': 0.25,\n",
    "    'use_chip_risk': 0.3,\n",
    "    'errors_en': 0.25,\n",
    "    'time_risk' : 0.2\n",
    "}\n",
    "\n",
    "# Calculate risk score (higher = riskier)\n",
    "td ['amount_risk'] = normalize(td['amount_norm']) * weights['amount']\n",
    "td ['u_chip_risk'] = normalize(td['use_chip_risk']) * weights['use_chip_risk']\n",
    "td ['errors_risk'] = normalize(td['errors_en']) * weights['errors_en']\n",
    "td ['time_risk'] = td['time_r'] * weights['time_risk']\n",
    "\n",
    "td['total_risk'] = (\n",
    "    td ['amount_risk'] + \n",
    "    td ['u_chip_risk'] + \n",
    "    td ['errors_risk'] +\n",
    "    td ['time_risk'] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td_s = td.sample(n=100000, random_state=42)\n",
    "\n",
    "time_risk_s = {\n",
    "    1: 100,\n",
    "    0.3: 50,\n",
    "    0: 20\n",
    "}\n",
    "td['time_risk_s'] = td['time_r'].map(time_risk_s)\n",
    "\n",
    "x = np.array(td['amount_norm'])\n",
    "y = np.array(td['total_risk'])\n",
    "colors = np.array(td['use_chip_risk'])\n",
    "sizes = np.array(td['time_risk_s'])\n",
    "\n",
    "plt.scatter(x,y, c= colors, cmap=\"Wistia\", s=sizes)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = td[['amount_norm', 'total_risk']].dropna()\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "td['cluster'] = kmeans.fit_predict(features)\n",
    "\n",
    "# Scatter plot with cluster color-coding\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=td,\n",
    "    x='amount_norm',\n",
    "    y='total_risk',\n",
    "    hue='cluster',\n",
    "    palette='Set1',\n",
    "    style='cluster',\n",
    "    size='time_risk_s',  # optional: vary size by time risk\n",
    "    sizes=(20, 200),\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "plt.title('Transaction Clusters by Amount and Risk')\n",
    "plt.xlabel('Normalized Amount (log scale)')\n",
    "plt.ylabel('Total Risk Score')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
